# LLM Cost Tracker

Application web multi-services pour suivre et analyser les coÃ»ts de diffÃ©rents fournisseurs LLM (OpenAI, Anthropic, Mistral, etc.) par projet et par pÃ©riode.

## Features

- ğŸŒ **Multi-services:** Architecture extensible supportant plusieurs providers LLM
- ğŸ¢ **Multi-workspaces:** Support des workspaces multiples (OpenAI: Edugami, Memoways, Storygami)
- ğŸ“Š **Workspace Total:** Vue des coÃ»ts globaux pour tous les projets d'un workspace
- ğŸ’° **Project Costs:** CoÃ»ts dÃ©taillÃ©s par projet avec breakdown par modÃ¨le
- ğŸ” **Model Breakdown:** Affichage des coÃ»ts par modÃ¨le (gpt-4o, gpt-4o-mini, etc.)
- ğŸ“… **PÃ©riodes flexibles:** Semaine, mois, annÃ©e ou sÃ©lection custom
- ğŸ”„ **Pagination complÃ¨te:** RÃ©cupÃ©ration de toutes les donnÃ©es mÃªme pour de longues pÃ©riodes
- ğŸ”’ **SÃ©curitÃ©:** ClÃ©s API stockÃ©es cÃ´tÃ© serveur uniquement (.env gitignored)
- ğŸ”Œ **Extensible:** Architecture provider permettant d'ajouter facilement de nouveaux services

## Services SupportÃ©s

### Actuellement ImplÃ©mentÃ©s
- âœ… **OpenAI** - 3 workspaces sÃ©parÃ©s (Edugami, Memoways, Storygami)

### Ã€ Venir
- â³ **Anthropic** - Console API
- â³ **Mistral** - Platform API
- â³ **Autres services LLM**

## Stack Technique

- **Framework:** Next.js 14+ (App Router)
- **Language:** TypeScript (strict mode)
- **Styling:** Tailwind CSS
- **DÃ©ploiement:** Vercel
- **Architecture:** Provider pattern avec interface commune

## Structure du Projet

```
llm-cost-tracker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                     # Pages et API routes Next.js
â”‚   â”‚   â”œâ”€â”€ page.tsx            # Page principale
â”‚   â”‚   â”œâ”€â”€ layout.tsx          # Layout global
â”‚   â”‚   â””â”€â”€ api/                # API endpoints
â”‚   â”‚       â”œâ”€â”€ providers/      # Liste des providers
â”‚   â”‚       â”œâ”€â”€ workspaces/     # Liste des workspaces (conditionnel)
â”‚   â”‚       â”œâ”€â”€ projects/       # Liste des projets
â”‚   â”‚       â””â”€â”€ costs/          # DonnÃ©es de coÃ»ts
â”‚   â”œâ”€â”€ components/             # Composants React
â”‚   â”‚   â”œâ”€â”€ ProviderSelector.tsx
â”‚   â”‚   â”œâ”€â”€ WorkspaceSelector.tsx
â”‚   â”‚   â”œâ”€â”€ ProjectSelector.tsx
â”‚   â”‚   â”œâ”€â”€ DateRangePicker.tsx
â”‚   â”‚   â”œâ”€â”€ CostDisplay.tsx
â”‚   â”‚   â””â”€â”€ ModelBreakdown.tsx
â”‚   â”œâ”€â”€ lib/                    # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ providers/         # Providers LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ interface.ts   # Interface ILLMProvider
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.ts      # OpenAIProvider
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic.ts   # AnthropicProvider (future)
â”‚   â”‚   â”‚   â”œâ”€â”€ mistral.ts     # MistralProvider (future)
â”‚   â”‚   â”‚   â””â”€â”€ factory.ts     # Provider factory
â”‚   â”‚   â””â”€â”€ types.ts           # Types TypeScript communs
â”‚   â””â”€â”€ utils/                  # Utilitaires
â”‚       â””â”€â”€ cache.ts           # SystÃ¨me de cache
â”œâ”€â”€ docs/                       # Documentation
â”‚   â””â”€â”€ plans/                 # Documents de design
â”œâ”€â”€ .env.local                 # Variables d'environnement (local)
â”œâ”€â”€ .env.example              # Template des variables
â””â”€â”€ README.md
```

## Installation et DÃ©veloppement Local

### PrÃ©requis

- Node.js 18+
- npm ou yarn
- ClÃ©s API pour les services LLM que vous souhaitez utiliser

### Setup Initial

1. **Cloner ou initialiser le projet:**
   ```bash
   cd "/Users/ulrich/Code projects/OpenAI Cost"
   ```

2. **Installer les dÃ©pendances:**
   ```bash
   npm install
   ```

3. **Configurer les variables d'environnement:**
   ```bash
   cp .env.example .env.local
   ```

   Ã‰diter `.env.local` et ajouter vos clÃ©s API:
   ```env
   # OpenAI (3 workspaces sÃ©parÃ©s)
   OPENAI_API_KEY_EDUGAMI=sk-proj-your-key-here
   OPENAI_API_KEY_MEMOWAYS=sk-proj-your-key-here
   OPENAI_API_KEY_STORYGAMI=sk-proj-your-key-here

   # Autres services (optionnel pour l'instant)
   # ANTHROPIC_API_KEY=sk-ant-your-key-here
   # MISTRAL_API_KEY=your-key-here
   ```

4. **Lancer le serveur de dÃ©veloppement:**
   ```bash
   npm run dev
   ```

5. **Ouvrir dans le navigateur:**
   ```
   http://localhost:3000
   ```

## DÃ©ploiement sur Vercel

### Ã‰tapes

1. **Initialiser Git (si pas dÃ©jÃ  fait):**
   ```bash
   git init
   git add .
   git commit -m "Initial commit"
   ```

2. **CrÃ©er un repo GitHub:**
   - CrÃ©er un nouveau repository sur GitHub
   - Suivre les instructions pour pusher le code

3. **Connecter Ã  Vercel:**
   - Aller sur [vercel.com](https://vercel.com)
   - Importer le repository GitHub
   - Vercel dÃ©tecte automatiquement Next.js

4. **Configurer les variables d'environnement:**
   - Dans Vercel: Project Settings â†’ Environment Variables
   - Ajouter les clÃ©s API pour OpenAI:
     - `OPENAI_API_KEY_EDUGAMI`
     - `OPENAI_API_KEY_MEMOWAYS`
     - `OPENAI_API_KEY_STORYGAMI`
   - (Optionnel) Ajouter les clÃ©s pour d'autres services:
     - `ANTHROPIC_API_KEY`
     - `MISTRAL_API_KEY`
   - Marquer toutes les clÃ©s comme "Secret"

5. **DÃ©ployer:**
   - Push sur `main` dÃ©clenche un dÃ©ploiement automatique
   - L'URL de production est fournie par Vercel

## SÃ©curitÃ©

âš ï¸ **Important:**
- Ne jamais commiter `.env.local` dans Git
- Les clÃ©s API sont accessibles uniquement cÃ´tÃ© serveur (API routes)
- Utiliser les variables d'environnement Vercel pour la production
- Les clÃ©s ne transitent jamais vers le client

## API Endpoints

### GET /api/providers

RÃ©cupÃ¨re la liste des providers LLM disponibles.

**Response:**
```json
{
  "providers": [
    {
      "id": "openai",
      "name": "OpenAI",
      "supportsWorkspaces": true
    }
  ]
}
```

### GET /api/workspaces

RÃ©cupÃ¨re la liste des workspaces pour un provider (si supportÃ©).

**Query params:**
- `provider`: ID du provider (ex: `openai`)

**Response:**
```json
{
  "workspaces": [
    { "id": "edugami", "name": "Edugami" },
    { "id": "memoways", "name": "Memoways" },
    { "id": "storygami", "name": "Storygami" }
  ]
}
```

### GET /api/projects

RÃ©cupÃ¨re la liste des projets.

**Query params:**
- `provider`: ID du provider
- `workspace`: ID du workspace (optionnel, requis si provider supporte workspaces)

**Response:**
```json
{
  "projects": [
    { "id": "proj_123", "name": "Project A" },
    { "id": "proj_456", "name": "Project B" }
  ]
}
```

### GET /api/costs

RÃ©cupÃ¨re les coÃ»ts pour un projet et une pÃ©riode.

**Query params:**
- `provider`: ID du provider
- `workspace`: ID du workspace (optionnel)
- `project_id`: ID du projet
- `start_date`: Date dÃ©but (ISO 8601)
- `end_date`: Date fin (ISO 8601)

**Response:**
```json
{
  "total_cost_usd": 53.68,
  "last_updated": "2025-12-22T10:30:00Z",
  "breakdown": [
    {
      "model": "gpt-4-turbo",
      "cost_usd": 45.23,
      "requests": 150
    },
    {
      "model": "gpt-3.5-turbo",
      "cost_usd": 8.45,
      "requests": 890
    }
  ]
}
```

## Architecture Provider

L'application utilise un pattern Provider pour supporter diffÃ©rents services LLM. Chaque provider implÃ©mente l'interface `ILLMProvider`:

```typescript
interface ILLMProvider {
  id: string;
  name: string;
  supportsWorkspaces: boolean;
  getWorkspaces(): Promise<Workspace[]>;
  getProjects(workspace?: string): Promise<Project[]>;
  getCosts(params: CostParams): Promise<CostData>;
}
```

### Ajouter un Nouveau Provider

1. CrÃ©er un nouveau fichier dans `src/lib/providers/`
2. ImplÃ©menter l'interface `ILLMProvider`
3. Ajouter le provider dans la factory (`src/lib/providers/factory.ts`)
4. Ajouter les variables d'environnement nÃ©cessaires

Voir la [documentation de design](docs/plans/2025-12-22-openai-cost-tracker-design.md) pour plus de dÃ©tails.

## Cache

- **DurÃ©e:** 5 minutes par dÃ©faut
- **ClÃ©:** `${provider}_${workspace}_${project}_${dateRange}`
- **Invalidation:** Bouton refresh manuel dans l'UI
- **Stockage:** En mÃ©moire (Map cÃ´tÃ© serveur)

## DÃ©veloppement

### Scripts disponibles

```bash
npm run dev          # Serveur de dÃ©veloppement
npm run build        # Build production
npm run start        # Serveur production
npm run lint         # Linter
```

### Technologies

- **Next.js:** Framework React avec SSR/SSG
- **TypeScript:** Typage statique
- **Tailwind CSS:** Utility-first CSS
- **React:** Library UI

## Support

Pour toute question ou problÃ¨me, consulter:
- [Documentation du design](docs/plans/2025-12-22-openai-cost-tracker-design.md)
- [Changelog](CHANGELOG.md)
- Documentation des APIs:
  - [OpenAI API](https://platform.openai.com/docs/api-reference)
  - [Anthropic API](https://docs.anthropic.com/en/api)
  - [Mistral API](https://docs.mistral.ai/)

## Roadmap

- [x] Architecture multi-provider extensible
- [x] Support OpenAI (3 workspaces)
- [x] ImplÃ©mentation complÃ¨te OpenAI avec pagination
- [x] Workspace Total (tous projets combinÃ©s)
- [x] Model-level breakdown avec pricing
- [ ] Support Anthropic
- [ ] Support Mistral
- [ ] Export des donnÃ©es (CSV, PDF)
- [ ] Graphiques et visualisations avancÃ©es
- [ ] Alertes de coÃ»ts

## License

PrivÃ© - Usage interne uniquement
